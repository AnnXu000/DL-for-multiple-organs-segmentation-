{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"GhostNet Module.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyOXGUY+6VPW3jCK9N6OU/d9"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"2BPTGGz7AqTx","colab_type":"code","colab":{}},"source":["from collections import namedtuple\n","import functools\n","import numpy as np\n","\n","import tensorflow as tf\n","\n","from tensorpack.models import (\n","    MaxPooling, GlobalAvgPooling, BatchNorm, Dropout, BNReLU, FullyConnected)\n","from tensorpack.tfutils import argscope\n","from tensorpack.models.common import layer_register\n","from tensorpack.utils.argtools import shape2d\n","\n","from imagenet_utils import ImageNetModel\n","\n","kernel_initializer = tf.contrib.layers.variance_scaling_initializer(2.0)\n","\n","slim = tf.contrib.slim"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"zaKyP2eRAWp2","colab_type":"code","colab":{}},"source":["class GhostNet(ImageNetModel):\n","    \"\"\"GhostNet model.\n","    \"\"\"\n","    def __init__(self, num_classes=1000, dw_code=None, ratio_code=None, se=1, data_format='NHWC', \n","                 width=1.0, depth=1.0, lr=0.2, weight_decay = 0.00004, dropout_keep_prob=0.8,\n","                 label_smoothing=0.0):\n","        self.scope = 'MobileNetV2'\n","        self.num_classes = num_classes\n","        self.dw_code = dw_code\n","        self.ratio_code = ratio_code\n","        self.se = se\n","        self.depth = depth\n","        self.depth_multiplier = width\n","        self.data_format = data_format\n","        self.lr = lr\n","        self.weight_decay = weight_decay\n","        self.dropout_keep_prob = dropout_keep_prob\n","        self.label_smoothing = label_smoothing\n","        self.image_shape = 224\n","\n","    def get_logits(self, inputs):\n","        sc = ghostnet_arg_scope(\n","            data_format=self.data_format,\n","            weight_decay=self.weight_decay,\n","            use_batch_norm=True,\n","            batch_norm_decay=0.9997,\n","            batch_norm_epsilon=0.001,\n","            regularize_depthwise=False)\n","        with slim.arg_scope(sc):\n","            with argscope(Conv2D, \n","                  kernel_initializer=kernel_initializer):\n","                with argscope([Conv2D, BatchNorm], data_format=self.data_format):\n","                    logits, end_points = ghost_net(\n","                        inputs,\n","                        dw_code=self.dw_code,\n","                        ratio_code=self.ratio_code,\n","                        se=self.se,\n","                        num_classes=self.num_classes,\n","                        dropout_keep_prob=self.dropout_keep_prob,\n","                        min_depth=8,\n","                        depth_multiplier=self.depth_multiplier,\n","                        depth=self.depth,\n","                        conv_defs=None,\n","                        prediction_fn=tf.contrib.layers.softmax,\n","                        spatial_squeeze=True,\n","                        reuse=None,\n","                        scope=self.scope,\n","                        global_pool=False)\n","                    return logits"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"E1mQg2gvAeGF","colab_type":"code","colab":{}},"source":["Conv = namedtuple('Conv', ['kernel', 'stride', 'depth', 'factor', 'se'])\n","Bottleneck = namedtuple('Bottleneck', ['kernel', 'stride', 'depth', 'factor', 'se'])\n","\n","# _CONV_DEFS specifies the GhostNet body\n","_CONV_DEFS_0 = [\n","    Conv(kernel=[3, 3], stride=2, depth=16, factor=1, se=0),\n","    Bottleneck(kernel=[3, 3], stride=1, depth=16, factor=1, se=0),\n","\n","    Bottleneck(kernel=[3, 3], stride=2, depth=24, factor=48/16, se=0),\n","    Bottleneck(kernel=[3, 3], stride=1, depth=24, factor=72/24, se=0),\n","\n","    Bottleneck(kernel=[5, 5], stride=2, depth=40, factor=72/24, se=1),\n","    Bottleneck(kernel=[5, 5], stride=1, depth=40, factor=120/40, se=1),\n","\n","    Bottleneck(kernel=[3, 3], stride=2, depth=80, factor=240/40, se=0),\n","    Bottleneck(kernel=[3, 3], stride=1, depth=80, factor=200/80, se=0),\n","    Bottleneck(kernel=[3, 3], stride=1, depth=80, factor=184/80, se=0),\n","    Bottleneck(kernel=[3, 3], stride=1, depth=80, factor=184/80, se=0),\n","\n","    Bottleneck(kernel=[3, 3], stride=1, depth=112, factor=480/80, se=1),\n","    Bottleneck(kernel=[3, 3], stride=1, depth=112, factor=672/112, se=1),\n","    Bottleneck(kernel=[5, 5], stride=2, depth=160, factor=672/112, se=1),\n","\n","    Bottleneck(kernel=[5, 5], stride=1, depth=160, factor=960/160, se=0),\n","    Bottleneck(kernel=[5, 5], stride=1, depth=160, factor=960/160, se=1),\n","    Bottleneck(kernel=[5, 5], stride=1, depth=160, factor=960/160, se=0),\n","    Bottleneck(kernel=[5, 5], stride=1, depth=160, factor=960/160, se=1),\n","\n","    Conv(kernel=[1, 1], stride=1, depth=960, factor=1, se=0),\n","    Conv(kernel=[1, 1], stride=1, depth=1280, factor=1, se=0)\n","]\n","\n","@layer_register(log_shape=True)\n","def DepthConv(x, kernel_shape, padding='SAME', stride=1, data_format='NHWC',\n","              W_init=None, activation=tf.identity):\n","    in_shape = x.get_shape().as_list()\n","    if data_format=='NHWC':\n","        in_channel = in_shape[3]\n","        stride_shape = [1, stride, stride, 1]\n","    elif data_format=='NCHW':\n","        in_channel = in_shape[1]\n","        stride_shape = [1, 1, stride, stride]\n","    out_channel = in_channel\n","    channel_mult = out_channel // in_channel\n","\n","    if W_init is None:\n","        W_init = kernel_initializer\n","    kernel_shape = shape2d(kernel_shape) #[kernel_shape, kernel_shape]\n","    filter_shape = kernel_shape + [in_channel, channel_mult]\n","\n","    W = tf.get_variable('W', filter_shape, initializer=W_init)\n","    conv = tf.nn.depthwise_conv2d(x, W, stride_shape, padding=padding, data_format=data_format)\n","    return activation(conv, name='output')\n","\n","    \n","def ghostnet_base(inputs,\n","                  final_endpoint=None,\n","                  min_depth=8,\n","                  depth_multiplier=1.0,\n","                  depth=1.0,\n","                  conv_defs=None,\n","                  output_stride=None,\n","                  dw_code=None,\n","                  ratio_code=None,\n","                  se=1,\n","                  scope=None):\n","    def depth(d):\n","        d = max(int(d * depth_multiplier), min_depth)\n","        d = round(d / 4) * 4\n","        return d\n","    \n","    end_points = {}\n","\n","    # Used to find thinned depths for each layer.\n","    if depth_multiplier <= 0:\n","        raise ValueError('depth_multiplier is not greater than zero.')\n","\n","    if conv_defs is None:\n","        conv_defs = _CONV_DEFS_0\n","        \n","    if dw_code is None or len(dw_code) < len(conv_defs):\n","        dw_code = [3] * len(conv_defs)\n","    print('dw_code', dw_code)\n","        \n","    if ratio_code is None or len(ratio_code) < len(conv_defs):\n","        ratio_code = [2] * len(conv_defs)\n","    print('ratio_code', ratio_code)\n","    \n","    se_code =  [x.se for x in conv_defs]\n","    print('se_code', se_code)\n","    \n","    if final_endpoint is None:\n","        final_endpoint = 'Conv2d_%d'%(len(conv_defs)-1)\n","\n","    if output_stride is not None and output_stride not in [8, 16, 32]:\n","        raise ValueError('Only allowed output_stride values are 8, 16, 32.')\n","        \n","    with tf.variable_scope(scope, 'MobilenetV2', [inputs]):\n","        with slim.arg_scope([slim.conv2d, slim.separable_conv2d], padding='SAME'):\n","            # The current_stride variable keeps track of the output stride of the\n","            # activations, i.e., the running product of convolution strides up to the\n","            # current network layer. This allows us to invoke atrous convolution\n","            # whenever applying the next convolution would result in the activations\n","            # having output stride larger than the target output_stride.\n","            current_stride = 1\n","\n","            # The atrous convolution rate parameter.\n","            rate = 1\n","            net = inputs\n","            in_depth = 3\n","            gi = 0\n","            for i, conv_def in enumerate(conv_defs):\n","                print('---')\n","                end_point_base = 'Conv2d_%d' % i\n","                if output_stride is not None and current_stride == output_stride:\n","                    # If we have reached the target output_stride, then we need to employ\n","                    # atrous convolution with stride=1 and multiply the atrous rate by the\n","                    # current unit's stride for use in subsequent layers.\n","                    layer_stride = 1\n","                    layer_rate = rate\n","                    rate *= conv_def.stride\n","                else:\n","                    layer_stride = conv_def.stride\n","                    layer_rate = 1\n","                    current_stride *= conv_def.stride\n","                    \n","                # change last bottleneck\n","                if i+2 == len(conv_defs):\n","                    end_point = end_point_base\n","                    net = Conv2D(end_point, net, depth(conv_def.depth), [1, 1], stride=1, \n","                                 data_format='NHWC', activation=BNReLU, use_bias=False)\n","                    \n","                    ksize = utils.ksize_for_squeezing(net, 1024)\n","                    net = slim.avg_pool2d(net, ksize, padding='VALID',\n","                                          scope='AvgPool_7')\n","                    end_points[end_point] = net\n","                    \n","                # Normal conv2d.\n","                elif i+1 == len(conv_defs):\n","                    end_point = end_point_base\n","                    net = Conv2D(end_point, net, 1280, conv_def.kernel, stride=conv_def.stride, \n","                                 data_format='NHWC', activation=BNReLU, use_bias=False)\n","                    end_points[end_point] = net\n","                    \n","                elif isinstance(conv_def, Conv):\n","                    end_point = end_point_base\n","                    net = Conv2D(end_point, net, depth(conv_def.depth), conv_def.kernel, stride=conv_def.stride, \n","                                 data_format='NHWC', activation=BNReLU, use_bias=False)\n","                    end_points[end_point] = net\n","\n","                # Bottleneck block.\n","                elif isinstance(conv_def, Bottleneck):\n","                    # Stride > 1 or different depth: no residual part.\n","                    if layer_stride == 1 and in_depth == conv_def.depth:\n","                        res = net\n","                    else:\n","                        end_point = end_point_base + '_shortcut_dw'\n","                        res = DepthConv(end_point, net, conv_def.kernel, stride=layer_stride, \n","                                        data_format='NHWC', activation=BNNoReLU)\n","                        end_point = end_point_base + '_shortcut_1x1'\n","                        res = Conv2D(end_point, res, depth(conv_def.depth), [1, 1], strides=1, data_format='NHWC',\n","                                     activation=BNNoReLU, use_bias=False)\n","                    \n","                    # Increase depth with 1x1 conv.\n","                    end_point = end_point_base + '_up_pointwise'\n","                    net = MyConv(end_point, net, depth(in_depth * conv_def.factor), [1, 1], dw_code[gi], ratio_code[gi], \n","                                 strides=1, data_format='NHWC', activation=BNReLU, use_bias=False)\n","                    end_points[end_point] = net\n","                    \n","                    # Depthwise conv2d.\n","                    if layer_stride > 1:\n","                        end_point = end_point_base + '_depthwise'\n","                        net = DepthConv(end_point, net, conv_def.kernel, stride=layer_stride, \n","                                        data_format='NHWC', activation=BNNoReLU)\n","                        end_points[end_point] = net\n","                    # SE\n","                    if se_code[i] > 0 and se > 0:\n","                        end_point = end_point_base + '_se'\n","                        net = SELayer(end_point, net, depth(in_depth * conv_def.factor), 4)\n","                        end_points[end_point] = net\n","                        \n","                    # Downscale 1x1 conv.\n","                    end_point = end_point_base + '_down_pointwise'\n","                    net = MyConv(end_point, net, depth(conv_def.depth), [1, 1], dw_code[gi], ratio_code[gi], strides=1, \n","                                 data_format='NHWC', activation=BNNoReLU if res is None else BNNoReLU, use_bias=False)\n","                    gi += 1\n","                        \n","                    # Residual connection?\n","                    end_point = end_point_base + '_residual'\n","                    net = tf.add(res, net, name=end_point) if res is not None else net\n","                    end_points[end_point] = net\n","\n","                # Unknown...\n","                else:\n","                    raise ValueError('Unknown convolution type %s for layer %d'\n","                                     % (conv_def.ltype, i))\n","                in_depth = conv_def.depth\n","                # Final end point?\n","                if final_endpoint in end_points:\n","                    return end_points[final_endpoint], end_points\n","\n","    raise ValueError('Unknown final endpoint %s' % final_endpoint)\n","\n","\n","def ghost_net(inputs,\n","                 num_classes=1000,\n","                 dropout_keep_prob=0.999,\n","                 is_training=True,\n","                 min_depth=8,\n","                 depth_multiplier=1.0,\n","                 depth=1.0,\n","                 conv_defs=None,\n","                 prediction_fn=tf.contrib.layers.softmax,\n","                 spatial_squeeze=True,\n","                 reuse=None,\n","                 scope='MobilenetV2',\n","                 global_pool=False,\n","                 dw_code=None,\n","                 ratio_code=None,\n","                 se=1,\n","                ):\n","    input_shape = inputs.get_shape().as_list()\n","    if len(input_shape) != 4:\n","        raise ValueError('Invalid input tensor rank, expected 4, was: %d' %\n","                         len(input_shape))\n","\n","    with tf.variable_scope(scope, 'MobilenetV2', [inputs], reuse=reuse) as scope:\n","        with slim.arg_scope([slim.batch_norm, slim.dropout],\n","                            is_training=is_training):\n","            net, end_points = ghostnet_base(inputs, scope=scope, dw_code=dw_code, ratio_code=ratio_code,\n","                                                se=se, min_depth=min_depth, depth=depth,\n","                                                depth_multiplier=depth_multiplier,\n","                                                conv_defs=conv_defs)\n","            with tf.variable_scope('Logits'):\n","                if not num_classes:\n","                    return net, end_points\n","                # 1 x 1 x 1280\n","                net = Dropout('Dropout_1b', net, keep_prob=dropout_keep_prob)\n","                logits = Conv2D('Conv2d_1c_1x1', net, num_classes, 1, strides=1, \n","                                 data_format='NHWC', activation=None)\n","                if spatial_squeeze:\n","                    logits = utils.spatial_squeeze(logits, scope='SpatialSqueeze')\n","            end_points['Logits'] = logits\n","            if prediction_fn:\n","                end_points['Predictions'] = prediction_fn(logits, scope='Predictions')\n","    return logits, end_points\n","\n","\n","def ghostnet_arg_scope(is_training=True,\n","                           data_format='NHWC',\n","                           weight_decay=0.00004,\n","                           use_batch_norm=True,\n","                           batch_norm_decay=0.99,\n","                           batch_norm_epsilon=0.001,\n","                           regularize_depthwise=False):\n","    batch_norm_params = {\n","        'decay': batch_norm_decay,\n","        'epsilon': batch_norm_epsilon,\n","        'updates_collections': tf.GraphKeys.UPDATE_OPS,\n","        'fused': True,\n","        'scale': True,\n","        'data_format': data_format,\n","        'is_training': is_training,\n","    }\n","    if use_batch_norm:\n","        normalizer_fn = slim.batch_norm\n","        normalizer_params = batch_norm_params\n","    else:\n","        normalizer_fn = None\n","        normalizer_params = {}\n","\n","    weights_regularizer = tf.contrib.layers.l2_regularizer(weight_decay)\n","    weights_initializer = kernel_initializer\n","    if regularize_depthwise:\n","        depthwise_regularizer = weights_regularizer\n","    else:\n","        depthwise_regularizer = None\n","    with slim.arg_scope([slim.conv2d, slim.separable_conv2d],\n","                        weights_initializer=weights_initializer,\n","                        activation_fn=tf.nn.relu,\n","                        normalizer_fn=normalizer_fn,\n","                        normalizer_params=normalizer_params):\n","        with slim.arg_scope([slim.batch_norm], **batch_norm_params):\n","            with slim.arg_scope([slim.conv2d], weights_regularizer=weights_regularizer):\n","                with slim.arg_scope([slim.separable_conv2d],\n","                                    weights_regularizer=depthwise_regularizer):\n","                    # Data format scope...\n","                    data_sc = utils.data_format_scope(data_format)\n","                    with slim.arg_scope(data_sc) as sc:\n","                        return sc"],"execution_count":null,"outputs":[]}]}